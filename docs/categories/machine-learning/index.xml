<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Octemull&#39;s Personal Site</title>
    <link>https://octemull.github.io/personal-site/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Octemull&#39;s Personal Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Sep 2018 19:18:01 +0800</lastBuildDate>
    
	<atom:link href="https://octemull.github.io/personal-site/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>在Matlab下利用Libsvm的输出模型画SVM三维特征的二分类曲面</title>
      <link>https://octemull.github.io/personal-site/post/svm-3d-boundary/</link>
      <pubDate>Thu, 27 Sep 2018 19:18:01 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/svm-3d-boundary/</guid>
      <description>前言 在做毕设的时候用到了支持向量机（SVM）做分类，当特征为3维的时候，想画一个分类面出来。因为在matlab中使用的Libsvm包，没有画三维分类面的功能，所以参考了stackoverflow上的一个问题，写了一下画三维分类曲面的程序。
所用软件  Matlab R2017b Libsvm-3.22 （安装在matlab的toolbox中）  所用数据    变量名 说明     model 用Libsvm建模输出的模型   train_data 标准化后的训练数据，每一行是一个样本，每一列是一个特征   train_target 样本标记，0-1向量    数据示例 说明  negative样本在前，positive样本在后 negative样本标记0，positive样本标记1 train_data已经标准化到-1、1之间（标准化后方便svm的训练和曲面的展示） 训练svm的核函数为RBF，若训练时使用了其他的核函数，则需要修改funRBF  train_data train_target 训练模型 model = svmtrain(train_target,train_data, [&#39;-t 2 -c 100 -g&#39;, num2str(1/3),&#39; -b 1 -q&#39;]);  代码 Main Code | 主代码 close all clear clc tic % 开始计时 %% load data 加载数据 load(&#39;model&#39;,&#39;train_data&#39;,&#39;train_target&#39;) Xdata_scaled = train_data; group = train_target; %% code GN3Dplot(Xdata_scaled,sum(group==0),sum(group==1),0,0,0,0); %plot samples 画三维图 xlabel(&#39;F1&#39;);ylabel(&#39;F3&#39;); zlabel(&#39;F6&#39;); ylim([-1 0]); yticks([-1 -0.</description>
    </item>
    
    <item>
      <title>Mac下matlab2014b安装libsvm</title>
      <link>https://octemull.github.io/personal-site/post/mac-libsvm/</link>
      <pubDate>Thu, 22 Mar 2018 20:56:49 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/mac-libsvm/</guid>
      <description>环境&amp;amp;软件说明  系统：macOS High Sierra 10.13.3 matlab版本：matlab2014b xcode版本：Xcode9.1， SDK版本10.13 （必须要有xcode才行） libsvm版本：libsvm3.22  下载libsvm 1）在libsvm主页下载最新的libsvm
2）直接在Downloads下解压
3）将解压后的文件夹复制到/Applications/MATLAB_R2014b.app/toolbox/下 （P.S. 从Finder中的Application里找到Matlab，右键显示包内容）
下载xcode、安装command line tool 1）安装command line tools：打开终端(Terminal)，输入
xcode-select --install  然后点击安装，等待下载安装即可。
2）确认xcode的SDK版本
从Finder进入 /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs ，
看到SDK版本为10.13（Xcode9.1）
3）修改xml文件【MATLAB2017b可跳过这一步直接编译】
 参考：https://blog.csdn.net/wukong1981/article/details/72805084） 因为matlab2014b不支持（自动识别）10.13版本的SDK，所以要在XML里添加几行
  打开matlab，在command window中输入  edit ([matlabroot &#39;/bin/maci64/mexopts/clang_maci64.xml&#39;])  查找&amp;quot;10.9&amp;quot;关键词，得到例如：
&amp;lt;dirExists name=&amp;quot; /Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk&amp;quot;/&amp;gt;&amp;lt;cmdReturnsname=&amp;quot;find/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk&amp;quot;/&amp;gt;&amp;lt;cmdReturnsname=&amp;quot;find -name MacOSX10.9.sdk&amp;quot; /&amp;gt;  在下面依次的加入10.12，10.13加好之后应该是这个样子的
&amp;lt;/XCODE_AGREED_VERSION&amp;gt; &amp;lt;ISYSROOT&amp;gt; &amp;lt;and&amp;gt; &amp;lt;cmdReturns name=&amp;quot;xcode-select -print-path&amp;quot;/&amp;gt; &amp;lt;or&amp;gt; &amp;lt;dirExists name=&amp;quot;$$/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk&amp;quot; /&amp;gt; &amp;lt;dirExists name=&amp;quot;$$/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.10.sdk&amp;quot; /&amp;gt; &amp;lt;dirExists name=&amp;quot;$$/Platforms/MacOSX.</description>
    </item>
    
    <item>
      <title>目录 周志华机器学习笔记</title>
      <link>https://octemull.github.io/personal-site/post/ml-contents/</link>
      <pubDate>Sun, 19 Nov 2017 15:59:40 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/ml-contents/</guid>
      <description> 目录  chap 01 - 绪论 chap 02 - 模型评估与选择 chap 03 - 线性模型 | Linear Model chap 04 - 决策树 | Decision Tree chap 05 - 神经网络 | Neural Network chap 06 - 支持向量机 | Support Vector Machine,SVM chap 07 - 贝叶斯分类器 | Bayesian Classifier chap 08 - 集成学习 | Ensemble learning chap 09 - 聚类 | Clustering chap 10 - 降维与度量学习 chap 11 - 特征选择（特征选取） 与 稀疏学习  </description>
    </item>
    
    <item>
      <title>chap 04 - 决策树 | Decision Tree</title>
      <link>https://octemull.github.io/personal-site/post/ml-chap04/</link>
      <pubDate>Mon, 13 Nov 2017 15:59:40 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/ml-chap04/</guid>
      <description>4.1 基本流程 适用任务：分类，以二分类为例
什么是决策树：
 基于树形结构来进行决策的一种处理过程； 经过该处理过程后形成的“决策树”，即决策流程。  决策树分解：
 先判断什么（父决策），后判断什么（子决策），最后导向什么（最终决策，对应判断结果）； 属性划分：每个“决策问题”都是对样本“属性”的划分； 范围缩小：每个“决策结果”导出的下一步决策都在上一决策的范围内； 举一个🌰，挑西瓜的决策树   如图，一棵决策树包含
 一个根结点——第一个决策问题，包含全部样本 若干内部结点——决策问题，包含经根节点划分后的部分样本 若干叶结点——决策结果，包含的部分样本均属于同一类别  从根节点到每个叶节点的路径对应了一个判定测试序列。
原则： 分而治之 divide-and-conquer
基本流程：
 说明： 14. 从A中去掉a*
 递归返回情形：
 (1)【Step 03】当前结点包含的样本均属于同一类，无需划分； (2)【Step 06】当前属性集为空(属性都用完了)，或者所有样本在属性集中取值相同，无法划分； (3)【Step 12】当前结点包含的样本集合为空，不能划分。  举🌰：挑西瓜，样本{色泽；根蒂；敲声；甜度；纹理；触感；……)
 (1) 常见 (2) 属性用完：当前结点的样本均为{色泽=青绿；根蒂=蜷缩；敲声=浊响}，类别为(好,坏,好,好,好,坏)，N(好)&amp;gt;N(坏)，则划分为“好瓜”。 取值相同：当前结点的样本{色泽=青绿；根蒂=(蜷缩, 蜷缩,蜷缩,蜷缩 )| (好,坏,好,好)}，划分属性A为“根蒂”，样本D在A上的属性值均为“蜷缩”，N(好)&amp;gt;N(坏)，所以均划分为“好”。 (3)上一步结点样本{色泽=青绿；根蒂=(蜷缩, 蜷缩,蜷缩)| (好，坏，好)}，原A={色泽，根蒂}，且在上一步已使用“色泽”属性划分，此时用“根蒂”划分，根蒂={硬挺, 蜷缩, 稍蜷}  情形2、3的处理：
 (2)把当前结点标记为叶结点，类别设定为该结点所含样本最多的类别. (3)把当前结点标记为叶结点，类别设定为其父节点所含类别最多的类别.  情形2、3的区别：
 (2) 利用当前结点的后验分布. (3) 把父节点的样本分布作为当前结点的先验分布.  4.</description>
    </item>
    
    <item>
      <title>chap 03 - 线性模型 | Linear Model</title>
      <link>https://octemull.github.io/personal-site/post/ml-chap03/</link>
      <pubDate>Fri, 10 Nov 2017 15:59:40 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/ml-chap03/</guid>
      <description>3.1 基本形式 给定由$d$个属性描述的样本$\boldsymbol{x}=(x_1,x_2,\cdots,x_d)^{\top}$，其中$x_i$是$\boldsymbol{x}$在第$i$个属性上的取值，线性模型视图习得一个通过属性的线性组合来进行预测的函数，即 $$f(\boldsymbol{x}) = w_1 x_1 + w_2 x_2 + \cdots + w_d x_d +b$$ 用向量形式表示为 $$f(\boldsymbol{x}) = \boldsymbol{w}^{\top} \boldsymbol{x} + \boldsymbol{b}$$ 其中，$\boldsymbol{w} = (w_1,w_2,\cdots, w_d)^{\top}$。模型由$ \boldsymbol{w}$和$ \boldsymbol{b}$确定。
特点：
 形式简单，易于建模，但蕴含着机器学习中一些重要的基本思想； 许多功能强大的非线性模型(nonlinear model)可在线性模型的基础上引入层级结构或者高维映射得到； ω直观表示出各属性的重要性，易于解释（有很好的可解释性 comprehensibility）。  例子：若在西瓜问题中学得“f好瓜(x) = 0.2 • x色泽+ 0.5 • x根蒂+ 0.3 • x敲声+ 1”，则意味着可通过综合考虑色泽、根蒂和敲声来判断瓜好不好，其中根蒂最要紧，而敲声比 色泽更重要.
3.2 线性回归 linear regression 目的：
习得一个线性模型尽可能准确的预测实值输出标记，即 $f(\boldsymbol{x}_i) = \boldsymbol{w}^{\top} \boldsymbol{x}_i + \boldsymbol{b}$，使$f(\boldsymbol{x})_i \simeq y_i $
符号说明：
 数据集 $D = {(\boldsymbol{x}_1,y_1), (\boldsymbol{x}_2,y_2), \cdots, (\boldsymbol{x}_m,y_m)}$.</description>
    </item>
    
    <item>
      <title>chap 02 - 模型评估与选择</title>
      <link>https://octemull.github.io/personal-site/post/ml-chap02/</link>
      <pubDate>Tue, 07 Nov 2017 15:59:40 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/ml-chap02/</guid>
      <description>2.1 经验误差与过拟合 基本概念：
 错误率 error rate：分类错误的样本数占总样本数的比例。如，在m个样本中有a个样本分类错误，则错误率E=a/m。 精度 accuracy：精度=1-错误率。如，续上，精度=1 - a/m。 误差 error：学习器的实际预测输出与样本真实值之间的差异。 训练误差 training error / 经验误差 empirical error：学习器在训练集上的误差。 泛化误差 generalization error：学习器在新样本（除训练集之外的样本）上的误差。
 过拟合 overfitting / 过配：学习器把训练样本学得“太好”了，很可能把训练样本特有的性质当做所有潜在样本具有的一般性质，以致于泛化性能下降。学习器学习能力过于强大。
 欠拟合 underfitting / 欠配：学习器对样本的普遍性质尚未学习完全。学习器的学习能力不足。
  机器学习的目标： * 学习的泛化误差小，即学习器对新样本的预测效果好。
过拟合是机器学习面临的关键障碍，只能“缓解”不可“避免” 过拟合是机器学习面临的关键障碍，各类学习算法都带有一些针对过拟合的措施；然而必须认识到，过拟合无法彻底避免，我们能做的只是“缓解”，或者说减小其风险。关于这一点，可以大致这样理解：机器学习面临的问题通常是NP难甚至更难，而有效的学习算法必然是在多项式时间内运行完成的，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了“P=NP”；因此，只要相信“P≠NP”，过拟合就不可避免。
2.2 评估方法 在现实任务中，我们往往有多种算法可以选择，甚至对同一个算法，当使用不同的参数配置时，也会产生不同的模型。“选什么样的模型、使用哪种参数配置？”就是机器学习中的“模型选择”( model selection )问题。自然地，理想的解决方案是对不同算法、不同参数配置的模型进行评估，选择泛化误差最小的那个模型。但泛化误差无法直接获取，而经验误差由于过拟合的存在不适合作为评判标准。那么，在现实任务中应该如何选择呢？
“测试误差”近似“泛化误差” 概念： * 测试集 testing set：从样本真实分布中独立同分布采样得到的样本的集合。
 注意：测试集应尽量与训练集互斥，即测试集中应尽量不出现训练集中已有的样本。 原因：测试集越是和训练集接近，其测试效果越没有说服力。如，老师上课讲了10道例题，考试时考的就是这10道原封不动的例题，自然没有办法测试出学生的真实水平，反映不出学生学得好不好。训练样本相当于练习题、例题，测试样本相当于考试题。老师都希望学生在学习上能够“举一反三”，就像我们希望训练的模型泛化能力强一样。
  测试误差 testing error：训练好的学习器对测试集中样本的预测值与测试集样本的真实值的误差。  但是，实际情况中，我们往往只有一个数据集。若全用来训练学习器，就没有多余的数据用来测试。同时，我们也很难保证在一样的条件下在总体中重新采样，获得新的样本。为了解决既要训练又要测试的问题，我们通常用一定的方法将数据集D划分为训练集S和测试集T，用于训练和测试模型。
2.2.1 留出法 hold-out 方法：
 直接将数据集D划分为两个互斥的集合，训练集S和测试集T。 T ∪ S = D 且，T ∩ S = ∅。  举🌰： 以二分类任务为例，假定D包含1000个样本，将其划分为S包含700个样本，T包含300个样本。用S进行训练后，如果模型在T上有90个样本分类错误，那么其错误率为$(90&amp;frasl;300)×100%=30%$，相应的，精确度为$1-30%=70%$。</description>
    </item>
    
    <item>
      <title>chap 01 - 绪论</title>
      <link>https://octemull.github.io/personal-site/post/ml-chap01/</link>
      <pubDate>Mon, 06 Nov 2017 15:59:40 +0800</pubDate>
      
      <guid>https://octemull.github.io/personal-site/post/ml-chap01/</guid>
      <description>1.1 引言——什么是“机器学习”（machine learning）  走在街上看天气、买西瓜的一天 —— 我们根据自己的经验对未知的事情做出了预测或判断 机器学习——将信息输入机器，由机器产生模型，从而对未知的事情做出预判 机器学习是研究“学习算法”的学问  1.2 基本术语 关于数据样本
 数据集 data set：一组描述不同个体的各种属性信息的集合 示例 instance / 样本 sample：一个个体、事件、对象。如，一个西瓜，一个机场。 属性 attribute / 特征 feature：反映事件或对象在某方面的表现或者性质的事项。如，色泽，敲声，是否成熟。 属性值 attribute value：属性的取值。如，颜色——红、黄、蓝&amp;hellip; 属性空间 attribute space / 样本空间 sample space / 输入空间：属性张成的空间。如，把西瓜的“色泽”“根蒂”“敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间。 特征向量 feature vector：示例在属性空间中的另一种叫法。续上，在该三维空间中，每个西瓜都可以用一个向量表示，空间中每一个点都对应一个向量坐标，即“特征向量”。 维数 dimensionality：在某数据集中，一个对象的属性的个数。续上上，西瓜数据集的维数 = 3，因为有三个不同的属性。  关于模型习得
 学习 learning / 训练 training：从数据中学习，通过某种算法得到模型的过程。如，从西瓜的特征里学习，得到预测西瓜是不是好瓜的模型。 训练数据 training data：输入进机器，用来得到模型的数据。如上，一些西瓜的“色泽”“根蒂”“敲声”属性及其取值。 训练样本 training sample：训练数据中的每一个样本。如上，每一个西瓜都是一个训练样本。 训练集 training set：训练样本组成的集合。如上，一堆西瓜。 假设 hypothesis：学得模型对应了关于数据的某种潜在规律。如，学得的模型可以通过西瓜的某些特征，判断西瓜是不是好瓜。 真相/真实 ground-truth：续上，事物的潜在规律本身。如，好瓜的真实规律。 学习器 learner：习得的模型的另一称呼。  关于预测 ( prediction )模型</description>
    </item>
    
  </channel>
</rss>